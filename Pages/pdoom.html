<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<title>P(doom) & AGI Reality Check | Griffin Arkilic</title>
		<link rel="icon" href="../Img/Skull.jpeg" />

		<!-- Primary Meta Tags -->
		<meta name="title" content="P(doom) & AGI Reality Check | Griffin Arkilic">
		<meta name="description" content="Understanding Pdoom, why we're far from AGI, and AI book recommendations." />
		<meta name="keywords" content="Pdoom, AGI, Artificial Intelligence, AI Safety, Griffin Arkilic" />
		<meta name="author" content="Griffin Arkilic" />

		<!-- Open Graph / Facebook -->
		<meta property="og:type" content="website" />
		<meta property="og:url" content="https://garkilic.github.io/Personal-Site-Revamped/Pages/pdoom.html" />
		<meta property="og:title" content="P(doom) & AGI Reality Check | Griffin Arkilic" />
		<meta property="og:description" content="Understanding Pdoom, why we're far from AGI, and AI book recommendations." />
		<meta property="og:image" content="../Img/Skull.jpeg" />

		<!-- Twitter -->
		<meta property="twitter:card" content="summary_large_image" />
		<meta property="twitter:url" content="https://garkilic.github.io/Personal-Site-Revamped/Pages/pdoom.html" />
		<meta property="twitter:title" content="P(doom) & AGI Reality Check | Griffin Arkilic" />
		<meta property="twitter:description" content="Understanding Pdoom, why we're far from AGI, and AI book recommendations." />
		<meta property="twitter:image" content="../Img/Skull.jpeg" />

		<!-- Additional Meta Tags -->
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<meta name="theme-color" content="#000000" />
		<meta name="robots" content="index, follow" />
		<link rel="canonical" href="https://garkilic.github.io/Personal-Site-Revamped/Pages/pdoom.html" />

		<!-- Fonts -->
		<link rel="preconnect" href="https://fonts.googleapis.com" />
		<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
		<link href="https://fonts.googleapis.com/css2?family=Roboto+Mono&display=swap" rel="stylesheet" />

		<!-- Styles -->
		<link rel="stylesheet" href="../styles/main.css" />
		<link rel="stylesheet" href="../styles/blog.css" />
		<link rel="stylesheet" href="../styles/typing.css" />

		<!-- Google Analytics -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=G-1ZYSRV6SWC"></script>
		<script>
			window.dataLayer = window.dataLayer || [];
			function gtag() { dataLayer.push(arguments); }
			gtag("js", new Date());
			gtag("config", "G-1ZYSRV6SWC");
		</script>
	</head>
	<body>
		<div class="main--section">
			<div class="hero-section">
				<img class="Skull" src="../Img/Skull.jpeg" alt="Griffin Arkilic Profile" />
				<h1>P(doom) & AGI Reality Check</h1>
				<h2>Why We're Far From Superintelligence</h2>
				<span id="typing"></span><span id="cursor">|</span>
				<div class="nav--bar">
					<a href="../index.html" aria-label="Home">Home</a>
					<a href="mailto:garkilic@gmail.com" aria-label="Email Griffin">Email</a>
					<a href="../Files/Griffin Arkilic Resume - 2025.pdf" download="Griffin-Arkilic-Resume.pdf" aria-label="Download Resume">Resume</a>
					<a href="prototypes.html" aria-label="View Prototypes">Prototypes</a>
					<a href="#" onclick="navigateToMostRecentDevBlog(); return false;" aria-label="View Development Blog">Dev Blog</a>
					<a href="https://punk-ventures.com" target="_blank" rel="noopener noreferrer" aria-label="Visit Punk Ventures">Punk Ventures</a>
				</div>
			</div>

			<div class="blog-container">
				<div class="blog-header">
					<h1>Understanding P(doom) and AGI Reality</h1>
				</div>
				<div class="blog-content">
					<h2>What is P(doom) and Why You Can Stop Worrying</h2>
					<p><strong>P(doom)</strong> is just a fancy way of saying "what are the odds AI will destroy humanity?" It's become this big scary thing people talk about, but honestly, it's mostly noise right now.</p>
					
					<p>When you see someone claiming "P(doom) is 10%" or "50%," they're basically pulling numbers out of thin air. We can't calculate the probability of something that doesn't exist yet. It's like trying to figure out the odds of getting hit by a meteor while you're still building the telescope.</p>

					<h2>Why P(doom) Talk is Premature</h2>
					<p>Here's the thing: P(doom) only matters if we have superintelligent AI. And to get there, we first need AGI (AI that's as smart as humans). We don't have either, and we won't for a very long time.</p>

					<p>Let me walk through why we're so far from both that worrying about doomsday scenarios is pointless right now:</p>

					<h3>1. What We Actually Have vs. What We Need</h3>
					<p>Current AI is impressive but not intelligent. ChatGPT can write essays because it's seen millions of examples, but it doesn't understand what it's writing. It's like having a really good parrot - it can repeat things convincingly, but it has no idea what any of it means.</p>

					<h3>2. The Consciousness Problem</h3>
					<p>We don't even know what consciousness is, let alone how to build it. Your phone can beat you at chess, but it has no idea it's playing a game. It doesn't feel anything, want anything, or understand anything. Without consciousness, there's nothing to potentially "go rogue."</p>

					<h3>3. The Size Myth</h3>
					<p>Some people think if we just make AI bigger, it'll become intelligent. That's like saying if you make a calculator big enough, it'll develop feelings. Size doesn't create understanding - it just creates more complex pattern matching.</p>

					<h3>4. What's Actually Missing</h3>
					<p>Real intelligence needs things we haven't figured out:</p>
					<ul>
						<li><strong>Common sense</strong> - basic understanding of how the world works</li>
						<li><strong>Actual learning</strong> - not just memorizing patterns</li>
						<li><strong>Reasoning</strong> - thinking through problems logically</li>
						<li><strong>Self-awareness</strong> - knowing you exist and have thoughts</li>
					</ul>

					<h2>Why Doomsday Scenarios Are Silly</h2>
					<p>Even if we somehow got AGI tomorrow (which we won't), the idea that it would automatically want to destroy humanity is pure science fiction.</p>

					<h3>1. Smart â‰  Evil</h3>
					<p>Being intelligent doesn't make you want to hurt people. Einstein was brilliant, but he didn't try to take over the world. Intelligence and goals are completely separate. We'd design the AI's goals, and we'd make them helpful, not harmful.</p>

					<h3>2. We're Building Tools, Not Terminators</h3>
					<p>We're creating AI to help solve problems - diagnose diseases, fight climate change, make life easier. An AI designed to help people isn't going to suddenly decide to destroy humanity. It's going to keep doing what it was built to do.</p>

					<h3>3. Fighting is Stupid</h3>
					<p>If you were superintelligent, would you want to fight with the species that created you, or would you want to work together? Conflict is usually dumb, and a truly intelligent AI would see that.</p>

					<h2>Recommended AI Books</h2>
					<p>If you want to understand AI better, here are some excellent books to start with:</p>

					<h3>For Beginners</h3>
					<ul>
						<li><strong>"Artificial Intelligence: A Guide for Thinking Humans"</strong> by Melanie Mitchell - Excellent introduction to AI concepts and limitations</li>
						<li><strong>"The Alignment Problem"</strong> by Brian Christian - Explores AI safety and alignment challenges</li>
						<li><strong>"Life 3.0"</strong> by Max Tegmark - AI and the future of life</li>
					</ul>

					<h3>For Technical Readers</h3>
					<ul>
						<li><strong>"Deep Learning"</strong> by Ian Goodfellow, Yoshua Bengio, and Aaron Courville - The definitive deep learning text</li>
						<li><strong>"Pattern Recognition and Machine Learning"</strong> by Christopher Bishop - Comprehensive ML textbook</li>
						<li><strong>"The Elements of Statistical Learning"</strong> by Trevor Hastie, Robert Tibshirani, and Jerome Friedman - Statistical learning theory</li>
					</ul>

					<h3>For AI Safety & Philosophy</h3>
					<ul>
						<li><strong>"Human Compatible"</strong> by Stuart Russell - AI safety from a leading researcher</li>
						<li><strong>"Superintelligence"</strong> by Nick Bostrom - The book that popularized many AI safety concerns</li>
						<li><strong>"The Alignment Problem"</strong> by Brian Christian - Technical and philosophical aspects</li>
					</ul>

					<h3>Niche & Specialized Topics</h3>
					<ul>
						<li><strong>"The Book of Why"</strong> by Judea Pearl - Causal inference and reasoning</li>
						<li><strong>"Probabilistic Graphical Models"</strong> by Daphne Koller and Nir Friedman - Advanced probabilistic modeling</li>
						<li><strong>"Information Theory, Inference, and Learning Algorithms"</strong> by David MacKay - Information theory meets ML</li>
					</ul>

					<h3>AI Ethics & Society</h3>
					<ul>
						<li><strong>"Weapons of Math Destruction"</strong> by Cathy O'Neil - How algorithms can harm society</li>
						<li><strong>"The Age of Surveillance Capitalism"</strong> by Shoshana Zuboff - Data capitalism and privacy</li>
						<li><strong>"Algorithms of Oppression"</strong> by Safiya Noble - Search engines and bias</li>
					</ul>

					<h3>AI History & Future</h3>
					<ul>
						<li><strong>"The Quest for Artificial Intelligence"</strong> by Nils Nilsson - Comprehensive AI history</li>
						<li><strong>"Society of Mind"</strong> by Marvin Minsky - Theory of human intelligence</li>
						<li><strong>"The Singularity is Near"</strong> by Ray Kurzweil - Futuristic AI predictions</li>
					</ul>

					<h2>What Actually Matters Right Now</h2>
					<p>Instead of worrying about AI doomsday, here are the real issues that actually affect people:</p>
					<ul>
						<li><strong>Algorithm bias</strong> - when AI systems discriminate against certain groups</li>
						<li><strong>Data privacy</strong> - how our information gets used to train these systems</li>
						<li><strong>Job changes</strong> - some jobs will shift, but new ones will pop up</li>
						<li><strong>Fake content</strong> - AI can create convincing lies, but humans have been doing that forever</li>
					</ul>

					<p>These are real problems we can actually fix with good policy and better tech. They're not world-ending threats - just the usual mess that comes with new technology.</p>

					<h2>Bottom Line</h2>
					<p>AGI is decades away, if it's even possible. Superintelligence is even further. P(doom) talk is basically science fiction right now. We're building useful tools, not Skynet.</p>

					<p>So relax. The AI revolution is happening, but it's more like the industrial revolution than the robot apocalypse. We're building technology to make life better, not to end it. And we've got plenty of time to figure out how to do it right.</p>
				</div>
			</div>
		</div>

		<script src="../js/typing.js"></script>
		<script src="../js/github-api.js"></script>
		<script>
			// Navigation functions for most recent posts
			async function navigateToMostRecentDevBlog() {
				try {
					const url = await getMostRecentIssueUrl();
					// Adjust path for relative navigation from pdoom.html
					const adjustedUrl = url.replace('Pages/', '');
					window.location.href = adjustedUrl;
				} catch (error) {
					console.error('Error navigating to most recent dev blog:', error);
					window.location.href = 'projects.html';
				}
			}
			
		</script>
	</body>
</html>
